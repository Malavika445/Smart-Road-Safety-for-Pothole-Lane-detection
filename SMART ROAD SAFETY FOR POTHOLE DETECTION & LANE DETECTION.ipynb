{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef52e76-8c3d-4509-86dc-b9df9dafff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.v8.detect.predict import DetectionPredictor\n",
    "from easygui import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "from lane import *\n",
    "import pygame\n",
    "\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(\"beep-125033.mp3\")\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c909fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0.21\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "print(ultralytics.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc2e22a-02c6-459a-90d3-b9eb7eaecfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neela\\python\\lib\\site-packages\\ultralytics\\nn\\tasks.py:332: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu')  # load\n"
     ]
    }
   ],
   "source": [
    "imgpoints, objpoints = collect_callibration_points()\n",
    "model = YOLO(\"best.pt\")\n",
    "def detect_lane(file_type):\n",
    "    \n",
    "    if file_type==\"image\":\n",
    "        path= fileopenbox(\"select the file\")\n",
    "        frame=cv2.imread(path)\n",
    "        img=process_image(frame,imgpoints, objpoints)\n",
    "        cv2.imshow(\"result\", img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            #cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return\n",
    "    elif file_type==\"vedio\":\n",
    "        path= fileopenbox(\"select the file\")\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        while(cap.isOpened()):\n",
    "             s, frame = cap.read()\n",
    "             try:\n",
    "                 img=process_image(frame,imgpoints, objpoints)\n",
    "                 cv2.imshow(\"result\", img)\n",
    "                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                     break\n",
    "             except:\n",
    "                 cv2.imshow(\"result\",frame)\n",
    "                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                     break\n",
    "             \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "            \n",
    "        while(cap.isOpened()):\n",
    "             s, frame = cap.read()\n",
    "             try:\n",
    "                 img=process_image(frame,imgpoints, objpoints)\n",
    "                 cv2.imshow(\"result\", img)\n",
    "                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                     break\n",
    "             except:\n",
    "                 cv2.imshow(\"result\",frame)\n",
    "                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                     break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "           \n",
    "def detect_pathholes(file_type):\n",
    "    \n",
    "    if file_type==\"image\":\n",
    "        path= fileopenbox(\"select the file\")\n",
    "        frame=cv2.imread(path)\n",
    "        results = model.predict(source=frame, show=True)\n",
    "        #cv2.imshow(\"result\", img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            #cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return\n",
    "    elif file_type==\"vedio\":\n",
    "        path= fileopenbox(\"select the file\")\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        while(cap.isOpened()):\n",
    "             s, frame = cap.read()\n",
    "             results = model.predict(source=frame, show=True)\n",
    "             try:\n",
    "                if not results[0].boxes.shape[0]==0:\n",
    "                    pygame.mixer.music.play()\n",
    "             except:\n",
    "                pass\n",
    "             #cv2.imshow(\"result\", img)\n",
    "             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                 break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "            \n",
    "        while(cap.isOpened()):\n",
    "             s, frame = cap.read()\n",
    "             results = model.predict(source=frame, show=True)\n",
    "             try:\n",
    "                if not results[0].boxes.shape[0]==0:\n",
    "                    pygame.mixer.music.play()\n",
    "             except:\n",
    "                pass\n",
    "             #cv2.imshow(\"result\", img)\n",
    "             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                 break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "\n",
    "   \n",
    "    \n",
    "def detect_both(file_type):\n",
    "    if file_type==\"image\":\n",
    "        path= fileopenbox(\"select the file\")\n",
    "        frame=cv2.imread(path)\n",
    "        img=process_image(frame,imgpoints, objpoints)\n",
    "        results = model.predict(source=img, show=True)\n",
    "        #img=process_image(frame,imgpoints, objpoints)\n",
    "        #cv2.imshow(\"result\", img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            #cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return\n",
    "    elif file_type==\"vedio\":\n",
    "        path= fileopenbox(\"select the file\")\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        #cap = cv2.VideoCapture(0)\n",
    "        #start=False\n",
    "    \n",
    "        while(cap.isOpened()):\n",
    "            s, frame = cap.read()\n",
    "            #img = cv2.imread(imagePath)\n",
    "            #gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \"\"\"\n",
    "            if not s:\n",
    "                continue\n",
    "            if start==False:\n",
    "                cv2.imshow(\"result\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('S'):\n",
    "                    start=True\n",
    "                continue\n",
    "            \"\"\" \n",
    "            #img=process_image(frame,imgpoints, objpoints)\n",
    "            #results = model.predict(source=img, show=True)\n",
    "            try:\n",
    "                img=process_image(frame,imgpoints, objpoints)\n",
    "                results = model.predict(source=img, show=True)\n",
    "            except:\n",
    "                results = model.predict(source=frame, show=True)\n",
    "            try:\n",
    "                if not results[0].boxes.shape[0]==0:\n",
    "                    pygame.mixer.music.play()\n",
    "            except:\n",
    "                pass\n",
    "            #print(\"type:\",type(results))\n",
    "            #cv2.imshow(\"result\", img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        #path= fileopenbox(\"select the file\")\n",
    "        #cap = cv2.VideoCapture(path)\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        start=False\n",
    "    \n",
    "        while(cap.isOpened()):\n",
    "            s, frame = cap.read()\n",
    "            #img = cv2.imread(imagePath)\n",
    "            #gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if not s:\n",
    "                continue\n",
    "            \"\"\"\n",
    "            if start==False:\n",
    "                cv2.imshow(\"result\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('S'):\n",
    "                    start=True\n",
    "                continue\n",
    "            \"\"\"\n",
    "            try:\n",
    "                img=process_image(frame,imgpoints, objpoints)\n",
    "                results = model.predict(source=img, show=True)\n",
    "            except:\n",
    "                results = model.predict(source=frame, show=True)\n",
    "            try:\n",
    "                if not results[0].boxes.shape[0]==0:\n",
    "                    pygame.mixer.music.play()\n",
    "            except:\n",
    "                pass\n",
    "            #print(\"type:\",type(results))\n",
    "            #cv2.imshow(\"result\", img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a929ca1-57e8-414d-a285-d1d7d3b9614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.21  Python-3.9.13 torch-2.5.1+cpu CPU\n",
      "Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Expected PIL/np.ndarray image type, but got <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13692\\1659851876.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mselect1\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"pathholes\"\u001b[0m \u001b[1;32mand\u001b[0m  \u001b[0mselect\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m\"exit\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;31m#path= fileopenbox(\"select the  file\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0mdetect_pathholes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mselect1\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"lane_pathholes\"\u001b[0m \u001b[1;32mand\u001b[0m  \u001b[0mselect\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m\"exit\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13692\\11701704.py\u001b[0m in \u001b[0;36mdetect_pathholes\u001b[1;34m(file_type)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfileopenbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"select the file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;31m#cv2.imshow(\"result\", img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\torch\\utils\\_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# only update args if predictor is already setup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msmart_inference_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\torch\\utils\\_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, source, model, stream)\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# merge list of Result into one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[1;34m(self, source, model)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;31m# setup source. Run every time predict is called\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;31m# check if save_dir/ label file exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_txt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    131\u001b[0m                                            transforms=getattr(self.model.model, 'transforms', None))\n\u001b[0;32m    132\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mfrom_img\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             self.dataset = LoadPilAndNumpy(source,\n\u001b[0m\u001b[0;32m    134\u001b[0m                                            \u001b[0mimgsz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                                            \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\ultralytics\\yolo\\data\\dataloaders\\stream_loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, im0, imgsz, stride, auto, transforms)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mim0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mim0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_single_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mim0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgsz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\ultralytics\\yolo\\data\\dataloaders\\stream_loaders.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mim0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mim0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_single_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mim0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgsz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\ultralytics\\yolo\\data\\dataloaders\\stream_loaders.py\u001b[0m in \u001b[0;36m_single_check\u001b[1;34m(im)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_single_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"Expected PIL/np.ndarray image type, but got {type(im)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Expected PIL/np.ndarray image type, but got <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "        while True:\n",
    "            imgpoints, objpoints = collect_callibration_points()\n",
    "            text = \"select one source \"\n",
    "                         # window title\n",
    "            title = \"lane and pathhole detection\"\n",
    "                         # item choices\n",
    "            choices = [\"image\", \"vedio\", \"cam\",\"exit\"]\n",
    "             \n",
    "            # creating a button box\n",
    "            select = choicebox(text, title, choices)\n",
    "            if select==\"exit\":\n",
    "                break\n",
    "            title1 = \"select lane and pathhole \"\n",
    "             \n",
    "            # item choices\n",
    "            choices1 = [\"lane\", \"pathholes\", \"lane_pathholes\",\"exit\"]\n",
    "            \n",
    "            text1=\"select the mode to detect\"\n",
    "            # creating a button box\n",
    "            select1 = choicebox(text1, title1, choices1)\n",
    "            if select1==\"lane\" and  select!=\"exit\":\n",
    "                #path= fileopenbox(\"select the file\")\n",
    "                try:\n",
    "                    detect_lane(file_type=select)\n",
    "                except:\n",
    "                    print(\"it does not contain lanes and cam is not focusing on road\")\n",
    "            elif select1==\"pathholes\" and  select!=\"exit\":\n",
    "                #path= fileopenbox(\"select the  file\")\n",
    "                detect_pathholes(file_type=select)\n",
    "                \n",
    "            elif select1==\"lane_pathholes\" and  select!=\"exit\":\n",
    "                #path= fileopenbox(\"select the  file\")\n",
    "                try:\n",
    "                    detect_both(file_type=select)\n",
    "                except:\n",
    "                    print(\"error there is no lane marks in the road\")\n",
    "            else :\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db49157-3ce5-4c68-94ea-165500e46519",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "if __name__==\"__main__\":\n",
    "        model = YOLO(\"best.pt\")\n",
    "        imgpoints, objpoints = collect_callibration_points()\n",
    "        cap = cv2.VideoCapture(\"demo_1.mp4\")\n",
    "        #cap = cv2.VideoCapture(0)\n",
    "        start=False\n",
    "    \n",
    "        while(cap.isOpened()):\n",
    "            \n",
    "            s, frame = cap.read()\n",
    "            #img = cv2.imread(imagePath)\n",
    "            #gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if not s:\n",
    "                continue\n",
    "            if start==False:\n",
    "                cv2.imshow(\"result\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('S'):\n",
    "                    start=True\n",
    "                continue\n",
    "            \n",
    "            #img=process_image(frame,imgpoints, objpoints)\n",
    "            results = model.predict(source=frame, show=True)\n",
    "            try:\n",
    "                if not results[0].boxes.shape[0]==0:\n",
    "                    pygame.mixer.music.play()\n",
    "            except:\n",
    "                pass\n",
    "            #print(\"type:\",type(results))\n",
    "            #cv2.imshow(\"result\", img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "print(ultralytics.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40667957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
